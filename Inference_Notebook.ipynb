{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Inference Notebook",
      "provenance": [],
      "collapsed_sections": [
        "tAmwnPYy8wdR",
        "4lcwmjM570tt",
        "LHcel-Ut8KCb",
        "qXzgcigi8o27",
        "-jTVp-gC8a-O"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dan-La/scientific-challenges-and-directions/blob/main/Inference_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ky5s7Oh-TQbR"
      },
      "source": [
        "# A notebook to perform inference on sentences with the challenge/direction labels\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAmwnPYy8wdR"
      },
      "source": [
        "## Installs and setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0PkpQrkcWPF",
        "outputId": "fb82eb34-66ed-4d98-d292-e832233a0470"
      },
      "source": [
        "### install/import\n",
        "import pip\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 77.3 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 92.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 722 kB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 54.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.2.1 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.10.3 transformers-4.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "r-hC9pFllvaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5xtLFSGgZ8s",
        "outputId": "94a56741-a6de-4b21-c8fd-269aa1e84d41"
      },
      "source": [
        "### check I am using a GPU\n",
        "from tensorflow.python.client import device_lib\n",
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()\n",
        "device_lib.list_local_devices()\n",
        "\n",
        "if torch.cuda.is_available():    \n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdqrvYFVfBVr",
        "outputId": "7d83a981-2059-4de2-d540-d68b0b5e2fba"
      },
      "source": [
        "import torch\n",
        "!python --version\n",
        "print(torch.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.12\n",
            "1.10.0+cu111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHcel-Ut8KCb"
      },
      "source": [
        "## Load the model from huggingface\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ne6uraVuP574"
      },
      "source": [
        "!pip install transformers \n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"DanL/scientific-challenges-and-directions\")\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"DanL/scientific-challenges-and-directions\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jTVp-gC8a-O"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### inference function\n",
        "def inference(sentences, model=model, threshold=0.5):\n",
        "    results = []\n",
        "    if len(sentences): # sentences != NULL\n",
        "        encoding = tokenizer(sentences, return_tensors=\"pt\", padding=True)\n",
        "        outputs = model(**encoding)\n",
        "        logits = outputs['logits'].sigmoid().cpu().detach().numpy()\n",
        "        for logit, text in zip(logits, sentences):\n",
        "            results.append({'sequence':text, 'output': {'challenge': logit[0], 'direction': logit[1]}})\n",
        "    return results"
      ],
      "metadata": {
        "id": "5ujIwpklq138"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### to play with the model insert your own sentences\n",
        "sentences = [\"we speculate that studying IL-6 will be beneficial.\",\n",
        "             \"severe atypical cases of pneumonia emerged and quickly spread worldwide.\",\n",
        "             \"in future studies, both PRRs should be tested as the cause for multiple deaths.\",\n",
        "             \"IbMADS1-transformed potatoes exhibited tuber morphogenesis in the fibrous roots.\",]\n",
        "\n",
        "results = inference(sentences, model=model)\n",
        "print(*results, sep='\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5_eD0FYrDFi",
        "outputId": "4fc2d5c7-27e4-43a2-9d65-85821c3c9b36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'sequence': 'we speculate that studying IL-6 will be beneficial.', 'output': {'challenge': 0.0003476635, 'direction': 0.99976546}}\n",
            "{'sequence': 'Severe atypical cases of pneumonia emerged and quickly spread worldwide.', 'output': {'challenge': 0.99971944, 'direction': 0.00024237744}}\n",
            "{'sequence': 'in future studies, both PRRs should be tested as the cause for multiple deaths.', 'output': {'challenge': 0.9997559, 'direction': 0.9998951}}\n",
            "{'sequence': 'IbMADS1-transformed potatoes exhibited tuber morphogenesis in the fibrous roots.', 'output': {'challenge': 0.00014355127, 'direction': 0.00014841928}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Further examples\n",
        "\n",
        "You can check out our dataset for further examples"
      ],
      "metadata": {
        "id": "WNTXFJc6txm5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### get the dataset \n",
        "!pip install datasets\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"DanL/scientific-challenges-and-directions-dataset\")"
      ],
      "metadata": {
        "id": "MuBsB4XztEyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### the first 10 train sentences\n",
        "sentences = dataset['test']['text'][:10]"
      ],
      "metadata": {
        "id": "M1zEB6zEts-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = inference(sentences, model=model)\n",
        "print(*results, sep='\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMuMEBHPuOkY",
        "outputId": "e8995ca8-c403-472e-c03c-ebfb0ef3ef51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'sequence': 'Interestingly, when R40 was\\nmutated to an aliphatic residue (Leu or Ala), the density of the D190\\nnegative charge would be enhanced and the proteolytic activity might\\nin theory be improved.', 'output': {'challenge': 0.00013575204, 'direction': 0.9991775}}\n",
            "{'sequence': 'Extending the health sector preparedness to include other sectors/disciplines (eg,\\nsocial services, critical infrastructure, regulatory authorities, public safety,\\njustice) is critical to a seamless response.', 'output': {'challenge': 0.00021095444, 'direction': 0.000119132936}}\n",
            "{'sequence': 'Both patients were treated with classical medical therapy including lactulose, but, despite increasing doses of lactulose for 3 days, ammonia levels remained unchanged.', 'output': {'challenge': 0.00012701421, 'direction': 0.000168087}}\n",
            "{'sequence': 'Briefly, the bait construct pGBKT7-SΔC was first transformed into the yeast strain AH109 using lithium acetate method described in the Clontech manual, and 100 µg of cDNA library DNA was sequentially transformed into the pGBKT7-SΔC-transformants.', 'output': {'challenge': 0.00017576803, 'direction': 0.00013076368}}\n",
            "{'sequence': 'Unfortunately, it was not possible to perform a bronchoalveolar lavage (BAL) because of the hemodynamic instability of the patient.', 'output': {'challenge': 0.99970716, 'direction': 0.00023564618}}\n",
            "{'sequence': 'Many of our virtual grand rounds have created unique opportunities for other institutional Departments and Centers to share their work.', 'output': {'challenge': 0.00013066796, 'direction': 0.00016652205}}\n",
            "{'sequence': 'Nevertheless, the value of these point of care tests seems obvious in countries with limited resources but perhaps also as the epidemic progresses in individuals in the form of self-homemade assay from a drop of blood on the fingertip.', 'output': {'challenge': 6.340194e-05, 'direction': 0.9945075}}\n",
            "{'sequence': 'These results are not congruent with previous studies showing colonization of bacteria in ID badges and lanyards3, 4, 5; however, there are certain factors that could explain the difference.', 'output': {'challenge': 0.9998673, 'direction': 0.99977595}}\n",
            "{'sequence': 'Based on further research and development, CB-20 might be developed as a novel diuretic.', 'output': {'challenge': 0.00048400497, 'direction': 0.99982053}}\n",
            "{'sequence': 'However, the calculated Gibbs free energy does not always correlate with frameshift efficiency.', 'output': {'challenge': 0.99968886, 'direction': 0.00023030375}}\n"
          ]
        }
      ]
    }
  ]
}